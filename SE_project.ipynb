{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting eye gaze using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing image processing and pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 213658 images\n"
     ]
    }
   ],
   "source": [
    "path_folders = \"/Users/dhirenkinha/Downloads/normalized\"\n",
    "folders_normalized = !ls $path_folders\n",
    "img_height, img_width = 36, 60\n",
    "eye_right_arr, eye_left_arr, gaze_right_arr, gaze_left_arr, pose_right_arr, pose_left_arr = np.empty((1,1,img_height,img_width)),np.empty((1,1,img_height,img_width)),np.empty((1,3)),np.empty((1,3)),np.empty((1,3)),np.empty((1,3))\n",
    "\n",
    "for idx_folder, folder in enumerate(folders_normalized):\n",
    "    path_files = path_folders + folder\n",
    "    files_normalized = !ls $path_files\n",
    "    \n",
    "    for idx_file, file_mat in enumerate(files_normalized):\n",
    "        file_normalized_path = path_files + \"/\" + file_mat\n",
    "        f = sio.loadmat(file_normalized_path)\n",
    "        data = f['data']\n",
    "        right_eye_img = data['right'][0,0]['image'][0,0]\n",
    "        left_eye_img = data['left'][0,0]['image'][0,0]\n",
    "        \n",
    "        right_eye_img = right_eye_img.reshape((right_eye_img.shape[0],1,right_eye_img.shape[1],right_eye_img.shape[2]))\n",
    "        left_eye_img = left_eye_img.reshape((left_eye_img.shape[0],1,left_eye_img.shape[1],left_eye_img.shape[2]))\n",
    "\n",
    "        eye_right_arr = np.vstack((eye_right_arr,right_eye_img))\n",
    "        eye_left_arr = np.vstack((eye_left_arr,left_eye_img))\n",
    "        gaze_right_arr = np.vstack((gaze_right_arr,data['right'][0,0]['gaze'][0,0]))\n",
    "        gaze_left_arr = np.vstack((gaze_left_arr,data['left'][0,0]['gaze'][0,0]))\n",
    "#         pose_right_arr = np.vstack((pose_right_arr,data['right'][0,0]['pose'][0,0]))\n",
    "#         pose_left_arr = np.vstack((pose_left_arr,data['left'][0,0]['pose'][0,0]))\n",
    "\n",
    "eye_right_arr = eye_right_arr[1:]\n",
    "eye_left_arr = eye_left_arr[1:]\n",
    "gaze_right_arr = gaze_right_arr[1:]\n",
    "gaze_left_arr = gaze_left_arr[1:]\n",
    "# pose_right_arr = pose_right_arr[1:]\n",
    "# pose_left_arr = pose_left_arr[1:]\n",
    "\n",
    "print(\"Loaded {} images\".format(len(eye_right_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have loaded 213658 right eye images and 213658 left eye images. Each eye image is of size 36x60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213658, 1, 36, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eye_right_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Let's build a CNN model to predict x,y,z coordinates of the eye gaze from given image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Following is the architecture used for this CNN model. Input image is a grayscale image of 1 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "class EyeGazeModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(50*6*12, 500)\n",
    "        self.fc2 = nn.Linear(500, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.pool1(F.relu(self.conv1(x)))\n",
    "        y2 = self.pool2(F.relu(self.conv2(y1)))\n",
    "        y3 = y2.view(-1, 50*6*12)\n",
    "        y4 = self.fc1(y3)\n",
    "        y5 = self.fc2(y4)\n",
    "        return y5\n",
    "\n",
    "model = EyeGazeModel().to(torch.double)\n",
    "Loss = nn.MSELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Conv2d: 1-1                            520\n",
      "├─MaxPool2d: 1-2                         --\n",
      "├─Conv2d: 1-3                            25,050\n",
      "├─MaxPool2d: 1-4                         --\n",
      "├─Linear: 1-5                            1,800,500\n",
      "├─Linear: 1-6                            1,503\n",
      "=================================================================\n",
      "Total params: 1,827,573\n",
      "Trainable params: 1,827,573\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Conv2d: 1-1                            520\n",
       "├─MaxPool2d: 1-2                         --\n",
       "├─Conv2d: 1-3                            25,050\n",
       "├─MaxPool2d: 1-4                         --\n",
       "├─Linear: 1-5                            1,800,500\n",
       "├─Linear: 1-6                            1,503\n",
       "=================================================================\n",
       "Total params: 1,827,573\n",
       "Trainable params: 1,827,573\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(images_train_data, labels_train_data, images_test_data, labels_test_data, epochs=5, batch_size=16):\n",
    "    train_loss_history = []\n",
    "    test_loss_history = []\n",
    "\n",
    "    loss_total = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "        loss_total = []\n",
    "        for i in range(0,len(labels_train_data),batch_size) :\n",
    "            images_train = images_train_data[i:i+batch_size]\n",
    "            labels_train = labels_train_data[i:i+batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            yhat = model(images_train)\n",
    "            loss = Loss(yhat,labels_train)\n",
    "            loss_total.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        train_loss_history.append(torch.mean(torch.DoubleTensor(loss_total)))\n",
    "        print(\"Train loss:\",train_loss_history[-1].item())\n",
    "        loss_total = []\n",
    "        for i in range(0,len(labels_test_data),batch_size) :\n",
    "            images_test = images_test_data[i:i+batch_size]\n",
    "            labels_test = labels_test_data[i:i+batch_size]\n",
    "            with torch.no_grad():\n",
    "                yhat_test = model(images_test)\n",
    "                loss_test = Loss(yhat_test,labels_test)\n",
    "                loss_total.append(loss_test)\n",
    "        test_loss_history.append(torch.mean(torch.DoubleTensor(loss_total)))\n",
    "#         print(\"Train loss:\",train_loss_history[-1].item(),\"Test loss:\",test_loss_history[-1].item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_arr = np.vstack((eye_left_arr/255, eye_right_arr/255))\n",
    "\n",
    "gaze_arr = np.vstack((gaze_left_arr, gaze_right_arr))\n",
    "\n",
    "images_train, images_test, labels_train, labels_test = train_test_split(eye_arr, gaze_arr, test_size=0.2)\n",
    "images_train = torch.DoubleTensor(images_train)\n",
    "labels_train = torch.DoubleTensor(labels_train)\n",
    "images_test = torch.DoubleTensor(images_test)\n",
    "labels_test = torch.DoubleTensor(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([341852, 1, 36, 60]) torch.Size([85464, 1, 36, 60])\n"
     ]
    }
   ],
   "source": [
    "print(images_train.size(), images_test.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have divided training and test samples in 80% and 20%. Training size is 341852 and test size is 85464."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "Train loss: 0.003591651489722652\n",
      "Epoch: 2/5\n",
      "Train loss: 0.0024288570776217168\n",
      "Epoch: 3/5\n",
      "Train loss: 0.002162747031906189\n",
      "Epoch: 4/5\n",
      "Train loss: 0.002017049263681232\n",
      "Epoch: 5/5\n",
      "Train loss: 0.0019204840840662898\n",
      "CPU times: user 2h 25min 17s, sys: 13min 15s, total: 2h 38min 32s\n",
      "Wall time: 1h 17min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(images_train, labels_train, images_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have 341852 images, the first loss itself is very less as we are using batch size of 16 images. Hence, 5 epochs were enough to train the model to get a good enough loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEGCAYAAACzYDhlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAw0ElEQVR4nO3deXxV1bn/8c+TgSQkIWAIGMjEKARUhAg4I1QFaYttbcUq1dZeq7W1o2NnX62tHbD1auvPW1stWpHrdGnFARWqrQwGRGXUMIcxBAhzIMnz++Ns4iEGSDAnO8P3/XqdF+fsvfbaz96aPFlrr7WOuTsiIiKxFBd2ACIi0vYp2YiISMwp2YiISMwp2YiISMwp2YiISMwlhB1AS9S1a1cvKCgIOwwRkVZlwYIF29w9q759Sjb1KCgooLi4OOwwRERaFTNbe7R96kYTEZGYU7IREZGYU7IREZGY0zMbEWlXDh06RGlpKQcOHAg7lFYrOTmZnJwcEhMTG3yMko2ItCulpaWkp6dTUFCAmYUdTqvj7pSXl1NaWkqvXr0afJy60USkXTlw4ACZmZlKNCfIzMjMzGx0y1DJRkTaHSWaj+dE7p+STRMq213Jz/6xhIp9h8IORUSkRVGyaUJluyt55M01PDC7JOxQRKSFKi8vZ8iQIQwZMoSTTz6Znj171n4+ePDgMY8tLi7m5ptvbtT5CgoK2LZt28cJuUlogEATKuzRic8NzeGR/6xh0sh8ck/qGHZIItLCZGZmsmjRIgB++tOfkpaWxve///3a/VVVVSQk1P+ruaioiKKiouYIs8mpZdPEvndxf+Li4DcvrQg7FBFpJa699lpuuOEGRowYwa233sr8+fM566yzOOOMMzj77LNZsSLy+2T27Nl88pOfBCKJ6itf+QqjRo2id+/e3Hfffcc9z+TJkxk8eDCDBw/m97//PQB79+5l/PjxnH766QwePJgnn3wSgNtvv53CwkJOO+20I5LhiVLLpollZ6Tw1XN7c/+sEq47txen53YOOyQROYqf/WMJSzfuatI6C3t04iefGtTo40pLS3nzzTeJj49n165dvPHGGyQkJPDKK69w55138vTTT3/kmOXLlzNr1ix2797NKaecwo033njUuS8LFizgr3/9K/PmzcPdGTFiBBdccAGrVq2iR48ePP/88wBUVFRQXl7Os88+y/LlyzEzdu7c2ejrqUstmxi4YVQfuqZ14BczluHuYYcjIq3A5z//eeLj44HIL/zPf/7zDB48mO985zssWbKk3mPGjx9PUlISXbt2pVu3bmzZsuWo9f/73//mM5/5DKmpqaSlpfHZz36WN954g1NPPZWZM2dy22238cYbb5CRkUFGRgbJyclcd911PPPMM3Ts+PEfCahlEwNpSQl86xP9+dFzi5m5dAsXDzo57JBEpB4n0gKJldTU1Nr3P/rRj7jwwgt59tlnWbNmDaNGjar3mKSkpNr38fHxVFVVNfq8/fv3Z+HChcyYMYMf/vCHjBkzhh//+MfMnz+fV199laeeeor777+f1157rdF1R1PLJkYmnplLn6xUfvXicg5V14Qdjoi0IhUVFfTs2ROARx55pEnqPO+883juuefYt28fe/fu5dlnn+W8885j48aNdOzYkauvvppbbrmFhQsXsmfPHioqKrj00ku59957eeeddz72+dWyiZHE+DjuGDeQr/6tmKnz1zHprIKwQxKRVuLWW2/lmmuu4ec//znjx49vkjqHDh3Ktddey/DhwwH46le/yhlnnMFLL73ELbfcQlxcHImJifzpT39i9+7dTJgwgQMHDuDuTJ48+WOf32L5TMHMxgJ/AOKBP7v7r+rsTwL+BgwDyoEr3H1NsO8O4DqgGrjZ3V8ys2TgdSCJSKJ8yt1/EpR/BLgAqAiqv9bdF1lkqusfgEuBfcH2hceKu6ioyJviy9PcnYkPzaVk6x5m3zKK9OSGL1onIrGxbNkyBg4cGHYYrV5999HMFrh7vWOzY9aNZmbxwAPAOKAQuNLMCusUuw7Y4e59gXuBe4JjC4GJwCBgLPDHoL5KYLS7nw4MAcaa2cio+m5x9yHBa1GwbRzQL3hdD/ypqa/1aMyMH4wfSPnegzz4r5XNdVoRkRYnls9shgMl7r7K3Q8CU4EJdcpMAB4N3j8FjAlaIhOAqe5e6e6rgRJguEfsCconBq/jNc0mAH8Ljp0LdDaz7I99dQ10Wk5nLhvSgz+/sZqNO/c312lFRFqUWCabnsD6qM+lwbZ6y7h7FZEusMxjHWtm8Wa2CNgKzHT3eVHlfmFm75rZvUEXXUPjwMyuN7NiMysuKytr1IUez/cvOQUHfvfy+01ar4icGE1J+HhO5P61utFo7l7t7kOAHGC4mQ0Odt0BDADOBE4CbmtkvQ+5e5G7F2VlZTVlyOR06ciXzyngmbdLWbyh4vgHiEjMJCcnU15eroRzgg5/n01ycnKjjovlaLQNQG7U55xgW31lSs0sAcggMlDguMe6+04zm0Xkmc5id98U7Ko0s78Ch9dXaEgcMff1UX2Z9tZ6fvnCMh67boSWOBcJSU5ODqWlpTR1D0Z7cvibOhsjlsnmLaCfmfUi8st9IvDFOmWmA9cAc4DLgdfc3c1sOvB3M5sM9CDycH++mWUBh4JEkwJcxIeDCrLdfVPwzOcyYHHUOb5hZlOBEUBFVGJqNhkpidw8ph8/+8dSZr9fxoWndGvuEEQESExMbNQ3TErTiFmycfcqM/sG8BKRoc9/cfclZnYXUOzu04GHgSlmVgJsJ5KQCMpNA5YCVcBN7l4dPNh/NBiZFgdMc/d/Bqd8PEhGBiwCbgi2zyAy7LmEyNDnL8fqmo/nqhH5PPrmGu5+fhnn9e1KQnyr68UUETkhMZ1n01o11Tyb+rzw3iZufHwhv/zsqVw5PC8m5xARCUMo82ykfmMHn8yw/C5Mnvk+eysbv46RiEhrpGTTzA5P9CzbXclDr68KOxwRkWahZBOCoXldGH9qNg+9voqtuw6EHY6ISMwp2YTk1rGnUFVTw+SZmugpIm2fkk1I8jNTmTSygGnF61mxeXfY4YiIxJSSTYi+ObovaUkJ/PKFZWGHIiISU0o2IeqS2oFvju7H7BVlvPGBZjOLSNulZBOyL52dT06XFO6esZzqGs15EpG2SckmZEkJ8dw6dgDLNu3i2bebfck2EZFmoWTTAnzqtGxOz8ngty+tYP/B6rDDERFpcko2LYCZceelA9m86wAP/1sTPUWk7VGyaSFG9M7k4sLu/Gn2Ssp2V4YdjohIk1KyaUFuGzeAA1U1/OFVTfQUkbZFyaYF6ZOVxlUj8nhi/npKtu4JOxwRkSajZNPCfGtMP1IS4/nVC8vDDkVEpMko2bQwmWlJ3DiqD68s28LcVeVhhyMi0iSUbFqg687tRXZGMnfPWEaNJnqKSBugZNMCJSfG8/2LT+Hd0gr+8e7GsMMREfnYlGxaqM+c0ZPC7E78+sUVHDikiZ4i0rop2bRQcXHGD8cPZMPO/Tz65pqwwxER+VhimmzMbKyZrTCzEjO7vZ79SWb2ZLB/npkVRO27I9i+wswuCbYlm9l8M3vHzJaY2c+iyj8elF1sZn8xs8Rg+ygzqzCzRcHrx7G85qZ0dt+uXHhKFvfPKmHH3oNhhyMicsJilmzMLB54ABgHFAJXmllhnWLXATvcvS9wL3BPcGwhMBEYBIwF/hjUVwmMdvfTgSHAWDMbGdT1ODAAOBVIAb4adZ433H1I8LqryS82hu64dCB7K6u477UPwg5FROSExbJlMxwocfdV7n4QmApMqFNmAvBo8P4pYIyZWbB9qrtXuvtqoAQY7hGHZzsmBi8HcPcZwX4H5gM5Mby2ZtO/ezpXnJnHlDlrWb1tb9jhiIickFgmm57A+qjPpcG2esu4exVQAWQe61gzizezRcBWYKa7z4uuMOg+mwS8GLX5rKDr7QUzG/Qxr6vZfeeifnRIiOPXL2qip4i0Tq1ugIC7V7v7ECItl+FmNrhOkT8Cr7v7G8HnhUB+0PX238Bz9dVrZtebWbGZFZeVtaxvzeyWnszXzu/DC4s3s2Dt9rDDERFptFgmmw1AbtTnnGBbvWXMLAHIAMobcqy77wRmEXmmQ1DHT4As4LtR5XYd7npz9xlAopl1rRusuz/k7kXuXpSVldWoC20O/3V+L7qlJ/Hz55cR6SkUEWk9Ypls3gL6mVkvM+tA5IH/9DplpgPXBO8vB14LnrlMByYGo9V6Af2A+WaWZWadAcwsBbgIWB58/ipwCXClu9ccPoGZnRw8B8LMhhO55la3DkzHDgl87+L+vL1uJzPe2xx2OCIijRKzZBM8g/kG8BKwDJjm7kvM7C4z+3RQ7GEg08xKiLRGbg+OXQJMA5YSefZyk7tXA9nALDN7l0gym+nu/wzqehDoDsypM8T5cmCxmb0D3AdM9FbaNLh8WC6ndE/nnheXc7Cq5vgHiIi0ENZKf+/GVFFRkRcXF4cdRr1mr9jKtX99ix99spDrzu0VdjgiIrXMbIG7F9W3r9UNEGjvLuifxXn9uvLfr31Axb5DYYcjItIgSjatjJlxx7iBVOw/xAOzS8IOR0SkQZRsWqHCHp343NAcHvnPGtZv3xd2OCIix6Vk00p97+L+xMXBb15aEXYoIiLHpWTTSmVnpPDVc3sz/Z2NLFq/M+xwRESOScmmFbthVB+6pnXgbk30FJEWTsmmFUtLSuDbn+jP/DXbmbl0S9jhiIgclZJNKzfxzFz6ZKXyqxeWc6haEz1FpGVSsmnlEuLjuGPcQFZt28vU+evCDkdEpF5KNm3AmIHdGNn7JO595QN2HdBETxFpeZRs2gAz4weXFrJ970EenL0y7HBERD5CyaaNODUng8uG9ODhf69m4879YYcjInIEJZs25PuXnIIDv31ZEz1FpGVRsmlDcrp05MvnFPDs2xtYvKEi7HBERGop2bQxXx/Vl84pidw9QxM9RaTlULJpYzJSErl5TD/eXFnO7BVlYYcjIgIo2bRJV43IpyCzI3fPWEaVJnqKSAugZNMGdUiI47axA/hg6x7+d0Fp2OGIiCjZtFVjB5/MsPwu/O7l99lbWRV2OCLSzinZtFFmxg/GD2Tbnkoeen1V2OGISDunZNOGDc3rwvhTs3no9VVs2XUg7HBEpB2LabIxs7FmtsLMSszs9nr2J5nZk8H+eWZWELXvjmD7CjO7JNiWbGbzzewdM1tiZj+LKt8rqKMkqLPD8c7RHtw69hSqamqY/PL7YYciIu1YzJKNmcUDDwDjgELgSjMrrFPsOmCHu/cF7gXuCY4tBCYCg4CxwB+D+iqB0e5+OjAEGGtmI4O67gHuDeraEdR91HO0F/mZqXzprAL+d8F6lm/eFXY4ItJOxbJlMxwocfdV7n4QmApMqFNmAvBo8P4pYIyZWbB9qrtXuvtqoAQY7hF7gvKJwcuDY0YHdRDUedlxztFufHN0X9KSEvjljOVhhyIi7VQsk01PYH3U59JgW71l3L0KqAAyj3WsmcWb2SJgKzDT3ecFx+wM6qh7rqOd4whmdr2ZFZtZcVlZ25oM2bljB745uh//er+MNz5oW9cmIq1Dqxsg4O7V7j4EyAGGm9ngJqr3IXcvcveirKyspqiyRfnS2fnkdEnhF88vo7pGy9iISPOKZbLZAORGfc4JttVbxswSgAygvCHHuvtOYBaRZzrlQOegjrrlj3aOdiUpIZ5bxw5g+ebdPLNQEz1FpHnFMtm8BfQLRol1IPLAf3qdMtOBa4L3lwOveWT1yOnAxGAkWS+gHzDfzLLMrDOAmaUAFwHLg2NmBXUQ1Pl/xzlHu/Op07I5Pbczv3v5ffYfrA47HBFpR2KWbILnI98AXgKWAdPcfYmZ3WVmnw6KPQxkmlkJ8F3g9uDYJcA0YCnwInCTu1cD2cAsM3uXSDKb6e7/DOq6DfhuUFdmUPdRz9EeRb7RcyCbdx3g4X9roqeINB9rp3/kH1NRUZEXFxeHHUbMXP+3Yv5Tso3Zt1xIVnpS2OGISBthZgvcvai+fa1ugIB8fLePG0BlVQ1/eFUTPUWkeSjZtEO9s9L44og8npi/npKte45/gIjIx6Rk0059a0w/UhLj+dULmugpIrGnZNNOZaYlceOoPryybAtzVra7keAi0syUbNqx687tRXZGMnfPWEaNJnqKSAwp2bRjyYnx3HLJKby3oYJ/vLsx7HBEpA1TsmnnLhvSk0E9OvHrF1dw4JAmeopIbCjZtHNxcZGJnht27ueRN9eEHY6ItFFKNsLZfbsyekA3HphVwva9B8MOR0TaICUbAeCOcQPYW1nFfa9+EHYoItIGKdkIAP26p3PFmXk8Nnctq7ftDTscEWljlGyk1ncu6keHhDh+/aImeopI01KykVrd0pP52vl9eGHxZorXbA87HBFpQ5Rs5Aj/dX4vuqUn8YsZy9CK4CLSVJRs5AgdOyTwvYv78/a6ncx4b3PY4YhIG9GgZGNmqWYWF7zvb2afNrPE2IYmYbl8WC6ndE/nnheXU1mliZ4i8vE1tGXzOpBsZj2Bl4FJwCOxCkrCFR9n3Dl+IOu27+OxuevCDkdE2oCGJhtz933AZ4E/uvvngUGxC0vCdkH/LM7r15X7Xv2Ain2Hwg5HRFq5BicbMzsLuAp4PtgWH5uQpKW4Y9xAdh04xAOzS8IORURauYYmm28DdwDPuvsSM+sNzIpZVNIiFPboxOeG5vDIf9awfvu+sMMRkVasQcnG3f/l7p9293uCgQLb3P3mGMcmLcD3Lu5PXBz8+qUVYYciIq1YQ0ej/d3MOplZKrAYWGpmtzTguLFmtsLMSszs9nr2J5nZk8H+eWZWELXvjmD7CjO7JNiWa2azzGypmS0xs29FlX/SzBYFrzVmtijYXmBm+6P2PdiQa5aI7IwU/uu83vzjnY0sWr8z7HBEpJVqaDdaobvvAi4DXgB6ERmRdlRmFg88AIwDCoErzaywTrHrgB3u3he4F7gnOLYQmEhkEMJY4I9BfVXA99y9EBgJ3HS4Tne/wt2HuPsQ4GngmajzrDy8z91vaOA1S+BrF/Sha1oH7n5eEz1F5MQ0NNkkBvNqLgOmu/sh4Hi/dYYDJe6+yt0PAlOBCXXKTAAeDd4/BYwxMwu2T3X3SndfDZQAw919k7svBHD33cAyoGd0hcHxXwCeaOC1yXGkJSXw7U/0Z/6a7by8dEvY4YhIK9TQZPP/gDVAKvC6meUDu45zTE9gfdTnUuokhugy7l4FVACZDTk26HI7A5hXp87zgC3uHr1Wfi8ze9vM/mVm59UXrJldb2bFZlZcVlZ2nEtrfyaemUufrFTueWE5h6prwg5HRFqZhg4QuM/de7r7pR6xFrgwxrEdlZmlEekq+3bQvRftSo5s1WwC8tz9DOC7wN/NrFPdOt39IXcvcveirKysWIXeaiXEx3HHuIGs2raXJ+ZroqeINE5DBwhkmNnkw3/5m9nviLRyjmUDkBv1OSfYVm8ZM0sAMoDyYx0bdOc9DTzu7tHPZQ7X8VngycPbgq648uD9AmAl0P+4Fy0fMWZgN0b2Ponfv/IBuw5ooqeINFxDu9H+Auwm8izkC0S60P56nGPeAvqZWS8z60Dkgf/0OmWmA9cE7y8HXvPIE+jpwMRgtFovoB8wP3ge8zCwzN0n13POTwDL3b308AYzywoGFxDMD+oHrGrgdUsUM+MHlxayfe9BHpy9MuxwRKQVSWhguT7u/rmozz87PLT4aNy9ysy+AbxEZLWBvwQTQu8Cit19OpHEMcXMSoDtRBISQblpwFIiI9BucvdqMzuXyCi496LOf6e7zwjeT+SjAwPOB+4ys0NADXCDu+vLWk7QqTkZXDakBw//ezVXj8ynR+eUsEMSkVbAGjKU1czmALe4+7+Dz+cAv3X3s2IcXyiKioq8uLg47DBarNId+xj9u3/xydOymfyFIWGHIyIthJktcPei+vY1tBvtBuCBYLLkGuB+4GtNFJ+0MjldOvLlcwp49u0NLN5QEXY4ItIKNHQ02jvufjpwGnBaMLJrdEwjkxbt66P60jklkbv1jZ4i0gCN+qZOd98VNdT4uzGIR1qJjJREbh7TjzdXljN7heYlicixfZyvhbYmi0JapatG5FOQ2ZG7ZyyjShM9ReQYPk6yUd9JO9chIY7bxw3gg617+N8Fpcc/QETarWMmGzPbbWa76nntBno0U4zSgl0y6GSK8rvwu5ffZ29lVdjhiEgLdcxk4+7p7t6pnle6uzd0jo60YWbGneMHsm1PJf/vdc2VFZH6fZxuNBEAhuZ1Yfxp2fzP66vYsutA2OGISAukZCNN4rZLBlBVU8Pkl98POxQRaYGUbKRJ5GV25EtnFTBtwXqWbz7et0+ISHujZCNN5puj+5KelMAvZywPOxQRaWGUbKTJdO7YgW+O7se/3i/jjQ800VNEPqRkI03qS2fnk9MlhV88v4zqGk3FEpEIJRtpUkkJ8dw6dgDLN+/mmYWa6CkiEUo20uQ+dVo2p+d25rcvr2D/weqwwxGRFkDJRppc5Bs9B7JlVyUP/1sTPUVEyUZiZHivk7i4sDt/mr2Sst2VYYcjIiFTspGYuX3cACqravj9K5roKdLeKdlIzPTOSuOLI/KY+tZ6SrbuDjscEQmRko3E1LfG9CMlMZ5fvaCJniLtWUyTjZmNNbMVZlZiZrfXsz/JzJ4M9s8zs4KofXcE21eY2SXBtlwzm2VmS81siZl9K6r8T81sg5ktCl6XHqsuaR6ZaUl8/cI+vLJsK3NWlocdjoiEJGbJxszigQeAcUAhcKWZFdYpdh2ww937AvcC9wTHFgITgUHAWOCPQX1VwPfcvRAYCdxUp8573X1I8JpxnLqkmXzlnF70yEjm7hnLqNFET5F2KZYtm+FAibuvcveDwFRgQp0yE4BHg/dPAWPMzILtU9290t1XAyXAcHff5O4LAdx9N7AM6HmcOOqtqwmuTxooOTGe719yCu9tqGD6OxvDDkdEQhDLZNMTWB/1uZSPJobaMu5eBVQAmQ05NuhyOwOYF7X5G2b2rpn9xcy6NCIOzOx6Mys2s+KyMq3r1dQuG9KTQT068ZuXVnDgkCZ6irQ3rXKAgJmlAU8D33b3w+vZ/wnoAwwBNgG/a0yd7v6Quxe5e1FWVlZThitAXFxkoueGnft55M01YYcjIs0slslmA5Ab9Tkn2FZvGTNLADKA8mMda2aJRBLN4+7+zOEC7r7F3avdvQb4Hz7sKmtIHNIMzu7bldEDuvHAayVs33sw7HBEpBnFMtm8BfQzs15m1oHIQ/rpdcpMB64J3l8OvObuHmyfGIxW6wX0A+YHz3MeBpa5++ToiswsO+rjZ4DFUef4SF1NdpXSKHeMG8Deg1Xc9+oHYYciIs0oIVYVu3uVmX0DeAmIB/7i7kvM7C6g2N2nE0kcU8ysBNhOJCERlJsGLCUyAu0md682s3OBScB7ZrYoONWdwcizX5vZEMCBNcDXjlVXrK5bjq1f93SuODOPx+au5ZqzC+jVNTXskESkGVikISHRioqKvLi4OOww2qytuw8w6jezOb9fFg9OGhZ2OCLSRMxsgbsX1bevVQ4QkNatW3oyXzu/Dy8u2Uzxmu1hhyMizUDJRkLxX+f3olt6Er+YsQy1rkXaPiUbCUXHDgl87+L+vL1uJ9dPWcCbJduUdETasJgNEBA5nsuH5VK6Yz9T5q5l5tIt9MlK5eqR+Xx2aA4ZKYlhhyciTUgDBOqhAQLN68Chap5/dxNT5q5l0fqdpCTGc9kZPbhqRD6De2aEHZ6INNCxBggo2dRDySY8izdU8NjctTy3aAMHDtVwRl5nvnRWPuMGZ5OcqPVTRVoyJZtGUrIJX8W+Qzy9sJTH5q5l1ba9dOmYyBfOzOXqEfnkntQx7PBEpB5KNo2kZNNyuDtvrixnypy1zFy2hRp3RvXPYtJZ+VzQvxvxcRZ2iCISULJpJCWblmlTxX6emL+eqfPXsXV3JTldUrhqRD5fKMohMy0p7PBE2j0lm0ZSsmnZDlXXMHPpFqbMWcucVeV0iI/j0lNPZtJZ+QzN60JkCT0RaW5KNo2kZNN6fLBlN4/PW8fTC0rZXVnFwOxOTBqZz4QhPUhN0sh+keakZNNISjatz97KKv5v0Ub+NmcNyzfvJj0pgc8Ny+HqkXn07ZYedngi7YKSTSMp2bRe7s7CdTuYMmctM97bzMHqGs7qncmks/K5qLA7ifFaNEMkVpRsGknJpm0o31PJtOLI8OkNO/fTLT2JK4fnceXwPE7OSA47PJE2R8mmkZRs2pbqGudf729lypy1zH6/jDgzLhrYnUln5XN2n0wNKBBpIsdKNnqCKm1efJwxekB3Rg/ozrryfTw+fy3T3lrPi0s20zsrlatH5PO5YVqPTSSW1LKph1o2bd+BQ9XMeC+yHtvb63aSnBjHZUN6cvVIrccmcqLUjdZISjbtS33rsV09Ip/xp2k9NpHGULJpJCWb9qli/yGeWVjKlLlrWVUWrMdWlMtVI/LJy9R6bCLHo2TTSEo27Zu7M2dlOVPmruXlpZH12C7on8WkkfmMOkXrsYkcjZJNIynZyGGbKw7wxPx1PBGsx9azcwpXjczjC0W5dNV6bCJHOFayiekMNzMba2YrzKzEzG6vZ3+SmT0Z7J9nZgVR++4Itq8ws0uCbblmNsvMlprZEjP7VlT535jZcjN718yeNbPOwfYCM9tvZouC14OxvGZpW07OSOY7F/XnP7eP5o9XDSU/syO/fnEFZ//yNb499W0WrN2ur7MWaYCYtWzMLB54H7gIKAXeAq5096VRZb4OnObuN5jZROAz7n6FmRUCTwDDgR7AK0B/oBuQ7e4LzSwdWABc5u5Lzexi4DV3rzKzewDc/bYggf3T3Qc3NHa1bORYSrbu5rG5H67HNuDkdCadlc9lQ3pqPTZp18Jq2QwHStx9lbsfBKYCE+qUmQA8Grx/ChhjkRl2E4Cp7l7p7quBEmC4u29y94UA7r4bWAb0DD6/7O5VQV1zgZwYXpu0Y327pfPTTw9i7p1j+OVnT8XM+MGzixlx96v85P8W88GW3WGHKNLixPLPsJ7A+qjPpcCIo5UJWiQVQGawfW6dY3tGHxi0WM4A5tVz7q8AT0Z97mVmbwO7gB+6+xt1DzCz64HrAfLy8o5zaSKQmpTAlcPzmHhmLgvX7eSxuWt5Yv56Hp2zlpG9T2LSyAIuHqT12ESgla4gYGZpwNPAt919V519PwCqgMeDTZuAPHcvN7NhwHNmNqjuce7+EPAQRLrRYn0N0naYGcPyuzAsvws/HD+QacWlPD5vLTf9fSFZ6UlceWYuV47IIzsjJexQRUITy2SzAciN+pwTbKuvTKmZJQAZQPmxjjWzRCKJ5nF3fya6MjO7FvgkMMaDh1HuXglUBu8XmNlKIs9/9FBGmlxmWhI3jurD9ef35vX3y5gydy3/PauEB2av5BMDuzFpZAHn9NV6bNL+xDLZvAX0M7NeRBLFROCLdcpMB64B5gCXE3nA72Y2Hfi7mU0mMkCgHzA/eJ7zMLDM3SdHV2RmY4FbgQvcfV/U9ixgu7tXm1nvoK5VTX+5Ih+KjzMuHNCNCwd0Y/32fTw+bx3Titfz0pIt9O6aylUj87l8aA4ZHbUem7QPMZ1nY2aXAr8H4oG/uPsvzOwuoNjdp5tZMjCFyLOX7cBEd18VHPsDIs9eqoh0l71gZucCbwDvATXBae509xlmVgIkEWkZAcwNRrl9DrgLOBQc8xN3/8ex4tZoNImFA4eqeWHxJqbMWcvCYD22Caf3ZNJZWo9N2gZN6mwkJRuJtcUbKnh83lqee3sj+w9VMyS3M5NGaj02ad2UbBpJyUaay+H12B6bu5aVZXvpXLseWx75malhhyfSKEo2jaRkI83N3ZmzqpzH5q7lpSVbqK75cD22CwdoPTZpHZRsGknJRsK0ueIAU9+KrMe2ZVdkPbYvjsjjijO1Hpu0bEo2jaRkIy3BoeoaXlm6hSlz1/LmynIS441xg7O5eFB3huV30bwdaXH0tdAirVBifBzjTs1m3KnZlGzdw+Pz1vLUglKmv7MRgB4ZyQwNJpMOy+/CwOxOWq1AWiy1bOqhlo20VIeqa1i2aRcL1u5gwdodLFy7g40VBwBITozj9JzOtclnaF4XuqR2CDliaU/UjdZISjbSmmzcuZ+F6z5MPks27qKqJvJz3TsrlWF5H7Z++mSlEafBBhIj6kYTacN6dE6hR+cUPnlaDwD2H6zm3dKdLFgXST6vLNvC/y4oBaBTckKk6y1IQKfndtbXIkiz0P9lIm1MSod4RvTOZETvTCAyrHr1tr2Rlk/QApq9ogyAOIOB2Z2O6HrL6ZKitdukyakbrR7qRpO2rmLfId5eH2n5LFi3g0XrdrL3YDUA3dKTPkw++V0Y1KMTSQla1UCOT91oInKEjI6JjDqlG6NO6QZAVXUNK7bsjiSfIAG9sHgzAB0S4jitZ0Zt8hma14WsdM33kcZRy6YeatmIwNZdB2q73Ras3cHiDbs4WB1Z/zY/syPD8rrUDr3u3z1dqxyIRqM1lpKNyEdVVlWzeMOu2tZP8dodbNtTCUBaUgJn5HVmaDDwYEheZzol6+sT2hslm0ZSshE5PnendMf+2pbPgrU7WL55FzUOZnBK9/QjRr7lZ3bUwIM2TsmmkZRsRE7Mnsoq3lm/88NJp+t2sPtAFQCZqR2OWPHg1J4Z+jqFNkYDBESkWaQlJXBO366c07crADU1TknZniNWPJi5dAsAifHGoB4ZtclnWH4XundKDjN8iSG1bOqhlo1I7JTvqeTtdZFJpwvW7uCd9TuprIoMPOjZOeWI5DPg5HQStN5bq6GWjYi0GJlpSXyisDufKOwOwMGqqPXe1u1g/urttYuNpiTGMyS3czDsOjIAoXNHrffWGqllUw+1bETCtXHn/iOe+yzZuIvqYL23PlmpR7R+enfVem8thVo2ItKqHF7v7VOnR9Z723ewindLK2qf+7y8dAvTiiPrvWWkJDI0r3PtpNMhuZ3p2EG/2lqamP4XMbOxwB+AeODP7v6rOvuTgL8Bw4By4Ap3XxPsuwO4DqgGbnb3l8wsNyjfHXDgIXf/Q1D+JOBJoABYA3zB3XdYZKzlH4BLgX3Ate6+MIaXLSJNrGOHBEb2zmRk1Hpvqw6v9xa0gGYF673FxxkDs9NrJ50WZnciL7OjltwJWcy60cwsHngfuAgoBd4CrnT3pVFlvg6c5u43mNlE4DPufoWZFQJPAMOBHsArQH+gG5Dt7gvNLB1YAFzm7kvN7NfAdnf/lZndDnRx99vM7FLgm0SSzQjgD+4+4lixqxtNpPWpu97b2+t2si9Y7y3OIKdLR3pnpdKrayq9u6bSOyuNXl1TOblTsrrhmkhY3WjDgRJ3XxUEMRWYACyNKjMB+Gnw/ing/qAlMgGY6u6VwGozKwGGu/scYBOAu+82s2VAz6DOCcCooK5HgdnAbcH2v3kkq841s85mlu3um2Jy1SISiqOt91aydQ8ry/ayetteVpXtYf7q7bVJCCKDEAq6ptI7K5KEekUloowUrYLQVGKZbHoC66M+lxJpWdRbxt2rzKwCyAy2z61zbM/oA82sADgDmBds6h6VQDYT6Wo7Whw9CZKWiLRNCfFxDOqRwaAeGUdsd3e27Kpk1bY9QQKKJKIlGyp4cfHm2oEIAF3TOgQtoTR6Ba2iPlmp5J6kbrnGapVP0cwsDXga+La776q7393dzBrVP2hm1wPXA+Tl5TVJnCLS8pgZJ2ckc3JGMmf36XrEvoNVNazbvq+2FbR6215WbdvLq8u3sq24srZcnEHuSR3pFdUS6h20jk7ulKxleeoRy2SzAciN+pwTbKuvTKmZJQAZRAYKHPVYM0skkmged/dnospsOdw9ZmbZwNZGxIG7PwQ8BJFnNo24ThFpIzokxNG3Wxp9u6XxYedIxK4Dh1gd1R23alvkfX3dcr26ptIrK7U2AfXqmkbvrNR2vThpLJPNW0A/M+tF5Jf7ROCLdcpMB64B5gCXA68FrZLpwN/NbDKRAQL9gPnB85yHgWXuPvkodf0q+Pf/orZ/I3hmNAKo0PMaEWmsTsmJnJ7bmdNzOx+xvbZbLkhAkW65PUftluvdNe0jySjvpFQ6JLTtlRJilmyCZzDfAF4iMvT5L+6+xMzuAordfTqRxDElGACwnUhCIig3jciD/yrgJnevNrNzgUnAe2a2KDjVne4+g0iSmWZm1wFrgS8E+2cQGYlWQmTo85djdc0i0v4c0S3Xt/5uudouuaBldKxuucPPh/oECamtdMtpBYF6aOiziMRaxf5DrNm2NzJQoWwvK7ftre2m23+o/m65PrUtokhCamndclpBQESkhclIqb9brqbG2bL7wBEJaNW2PSzeUMEL720iqlfuiG652jlEWWnkndSxxXXLKdmIiLQgcXFGdkYK2RkpR+mWi3THrYpKRK8u38KTxQc/rCPolovMG0qrnUPUOyuN7p2SQumWU7IREWklIqPl0unbLf0j+yr2H2L1tsjghMPJaFXZXuasKufAoZrach07xFOQmXpEAjrcTRfLbjklGxGRNiAjJZEhuZ0ZUk+33OZdB2rnDB0erPBuaQUzPtItl8RlQ3rww08WNnl8SjYiIm1YXJzVrqJ9Tp1uucqqataV76udM7SqbA/ZnVNiEoeSjYhIO5WUEE+/7un06/7Rbrmm1rKGK4iISJukZCMiIjGnZCMiIjGnZCMiIjGnZCMiIjGnZCMiIjGnZCMiIjGnZCMiIjGnrxioh5mVEflOnBPVFdjWROE0JcXVOIqrcRRX47TFuPLdPau+HUo2MWBmxUf7TocwKa7GUVyNo7gap73FpW40ERGJOSUbERGJOSWb2Hgo7ACOQnE1juJqHMXVOO0qLj2zERGRmFPLRkREYk7JRkREYk7J5gSZ2V/MbKuZLT7KfjOz+8ysxMzeNbOhLSSuUWZWYWaLgtePmyGmXDObZWZLzWyJmX2rnjLNfr8aGFez36/gvMlmNt/M3gli+1k9ZZLM7Mngns0zs4IWEte1ZlYWdc++Guu4gvPGm9nbZvbPevY1+71qYFyh3Kvg3GvM7L3gvMX17G/an0l31+sEXsD5wFBg8VH2Xwq8ABgwEpjXQuIaBfyzme9VNjA0eJ8OvA8Uhn2/GhhXs9+v4LwGpAXvE4F5wMg6Zb4OPBi8nwg82ULiuha4P4R79l3g7/X99wrjXjUwrlDuVXDuNUDXY+xv0p9JtWxOkLu/Dmw/RpEJwN88Yi7Q2cyyW0Bczc7dN7n7wuD9bmAZ0LNOsWa/Xw2MKxTBfdgTfEwMXnVH80wAHg3ePwWMMTNrAXE1OzPLAcYDfz5KkWa/Vw2MqyVr0p9JJZvY6Qmsj/pcSgv5RQacFXSDvGBmg5rzxEH3xRlE/iKOFur9OkZcENL9CrpfFgFbgZnuftR75u5VQAWQ2QLiAvhc0PXylJnlxjom4PfArUDNUfaHcq8aEBc0/706zIGXzWyBmV1fz/4m/ZlUsml/FhJZv+h04L+B55rrxGaWBjwNfNvddzXXeY/nOHGFdr/cvdrdhwA5wHAzG9xc5z6WBsT1D6DA3U8DZvJhiyImzOyTwFZ3XxDL8zRWA+Nq1ntVx7nuPhQYB9xkZufH8mRKNrGzAYj+KyUn2BYqd991uBvE3WcAiWbWNdbnNbNEIr/QH3f3Z+opEsr9Ol5cYd2vOjHsBGYBY+vsqr1nZpYAZADlYcfl7uXuXhl8/DMwLMahnAN82szWAFOB0Wb2WJ0yYdyr48YVwr2KPveG4N+twLPA8DpFmvRnUskmdqYDXwpGdIwEKtx9U9hBmdnJh/uqzWw4kf8HYvpDF5zvYWCZu08+SrFmv18NiSuM+xWcK8vMOgfvU4CLgOV1ik0HrgneXw685sGT3TDjqtOv/2kiz8Jixt3vcPccdy8g8vD/NXe/uk6xZr9XDYmrue9V1HlTzSz98HvgYqDuCNYm/ZlMOOFo2zkze4LISKWuZlYK/ITIw1Lc/UFgBpHRHCXAPuDLLSSuy4EbzawK2A9MjPUPHZG/8CYB7wV9/QB3AnlRcYVxvxoSVxj3CyIj5R41s3giCW6au//TzO4Cit19OpFEOcXMSogMCpnYQuK62cw+DVQFcV3bDHF9RAu4Vw2JK6x71R14Nvg7KgH4u7u/aGY3QGx+JrVcjYiIxJy60UREJOaUbEREJOaUbEREJOaUbEREJOaUbEREJOaUbESakZlVR63wu8jMbm/CugvsKKt9i4RN82xEmtf+YKkXkXZFLRuRFiD4bpFfB98vMt/M+gbbC8zstWChxlfNLC/Y3t3Mng0WCH3HzM4Oqoo3s/+xyHfNvBzM8sfMbrbI9/a8a2ZTQ7pMaceUbESaV0qdbrQrovZVuPupwP1EVguGyOKfjwYLNT4O3Bdsvw/4V7BA6FBgSbC9H/CAuw8CdgKfC7bfDpwR1HNDbC5N5Oi0goBIMzKzPe6eVs/2NcBod18VLA662d0zzWwbkO3uh4Ltm9y9q5mVATlRizge/pqEme7eL/h8G5Do7j83sxeBPURWrX4u6jtpRJqFWjYiLYcf5X1jVEa9r+bD57LjgQeItILeClY+Fmk2SjYiLccVUf/OCd6/yYeLRl4FvBG8fxW4EWq/zCzjaJWaWRyQ6+6zgNuILK//kdaVSCzprxuR5pUStcI0wIvufnj4cxcze5dI6+TKYNs3gb+a2S1AGR+uvPst4CEzu45IC+ZG4GjLv8cDjwUJyYD7gu+iEWk2emYj0gIEz2yK3H1b2LGIxIK60UREJObUshERkZhTy0ZERGJOyUZERGJOyUZERGJOyUZERGJOyUZERGLu/wNmXqeJz7F9CAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( range(1,6), train_loss_history, label = \"Train loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0018882664221587114\n"
     ]
    }
   ],
   "source": [
    "batch_size=16\n",
    "test_loss_history = []\n",
    "loss_total = []\n",
    "yhat = np.array([0,0,0])\n",
    "for i in range(0,len(labels_test),batch_size) :\n",
    "    images_test_batch = images_test[i:i+batch_size]\n",
    "    labels_test_batch = labels_test[i:i+batch_size]\n",
    "    with torch.no_grad():\n",
    "        yhat_test = model(images_test_batch)\n",
    "        yhat = np.vstack((yhat, yhat_test.numpy()))\n",
    "        loss_test = Loss(yhat_test,labels_test_batch)\n",
    "        loss_total.append(loss_test)\n",
    "test_loss_history.append(torch.mean(torch.DoubleTensor(loss_total)))\n",
    "print(\"Test loss:\",test_loss_history[-1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'fully_trained_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are saving the trained model and using it later on test images taken from a webcam in a different file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps are to test the model on live test images taken from webcam."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
